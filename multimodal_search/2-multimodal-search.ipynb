{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet langchain langchain_community langchain_aws gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT_PATH = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from functools import wraps\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from common.aws.embedding import BedrockEmbedding\n",
    "from common.aws.claude import BedrockClaude\n",
    "from common.utils.images import encode_image_base64, encode_image_base64_from_file, display_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"oss_policies_info.json\", \"r\") as f:\n",
    "    saved_data = json.load(f)\n",
    "\n",
    "host = saved_data[\"opensearch_host\"]\n",
    "index_name = saved_data[\"opensearch_index_name\"]\n",
    "vector_store_name = saved_data[\"vector_store_name\"]\n",
    "encryption_policy = saved_data[\"encryption_policy\"]\n",
    "network_policy = saved_data[\"network_policy\"]\n",
    "access_policy = saved_data[\"access_policy\"]\n",
    "\n",
    "print(f\"\"\"OpenSearch Host: {host}\\n \\\n",
    "        Index Name    : {index_name}\"\"\")\n",
    "\n",
    "print(f\"\"\"Vector Store Name: {vector_store_name}\\n \\\n",
    "        Encryption Policy: {encryption_policy}\\n \\\n",
    "        Network Policy   : {network_policy} \\n \\\n",
    "        Access Policy    : {access_policy}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize boto3 session ## \n",
    "boto3_session = boto3.session.Session(region_name='us-west-2')\n",
    "print(f'The notebook will use aws services hosted in {boto3_session.region_name} region')\n",
    "\n",
    "# initialize boto3 clients for required AWS services\n",
    "sts_client = boto3_session.client('sts')\n",
    "s3_client = boto3_session.client('s3')\n",
    "opensearchservice_client = boto3_session.client('opensearchserverless')\n",
    "\n",
    "service = 'aoss'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWSV4SignerAuth(credentials, boto3_session.region_name, service)\n",
    "\n",
    "# initiailize a SageMaker role ARN \n",
    "sagemaker_role_arn = sagemaker.get_execution_role()\n",
    "\n",
    "bedrock_embedding = BedrockEmbedding(region=boto3_session.region_name)\n",
    "\n",
    "oss_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검색 결과 시각화를 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_search_results(documents):\n",
    "    data = []\n",
    "    for _, doc in enumerate(documents):\n",
    "        source = doc.get('_source', {})\n",
    "        metadata = source.get('metadata', {})\n",
    "        score = doc.get('_score', 0)\n",
    "\n",
    "        img_res = s3_client.get_object(\n",
    "            Bucket=\"amazon-berkeley-objects\",\n",
    "            Key=f\"images/small/{metadata.get('image_url', '')}\"\n",
    "        )\n",
    "                \n",
    "        img = Image.open(BytesIO(img_res['Body'].read()))\n",
    "        img_base64 = encode_image_base64(img) if img else ''\n",
    "\n",
    "        data.append({\n",
    "            'thumbnail': f'<img src=\"data:image/png;base64,{img_base64}\" width=\"50\" height=\"50\">' if img_base64 else '',\n",
    "            'item_name': metadata.get('item_name', ''),\n",
    "            'item_id': metadata.get('item_id', ''),\n",
    "            'image_url': metadata.get('image_url', ''),\n",
    "            'description': source.get('description', ''),\n",
    "            'score': score\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    display(HTML(df.to_html(escape=False, index=False)))\n",
    "\n",
    "\n",
    "def log_query_and_results(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        text = kwargs.get('text', None) if 'text' in kwargs else None\n",
    "        image = kwargs.get('image', None) if 'image' in kwargs else None\n",
    "\n",
    "        print('======= Query ========')\n",
    "        print(text)\n",
    "        if image:\n",
    "            display_image(image)\n",
    "\n",
    "        docs = func(*args, **kwargs)\n",
    "\n",
    "        print('======= Results ========')\n",
    "        show_search_results(docs)\n",
    "        \n",
    "        return docs\n",
    "    \n",
    "    return wrapper\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector 검색 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Function for semantic search capability using knn on input query prompt.\n",
    "\"\"\"\n",
    "@log_query_and_results\n",
    "def find_similar_items(oss_client,\n",
    "                        bedrock_embedding: BedrockEmbedding,\n",
    "                        index_name: str,\n",
    "                        k: int = 5,\n",
    "                        text: str = None,\n",
    "                        image: str = None):\n",
    "    \"\"\"\n",
    "    Main semantic search capability using knn on input query prompt.\n",
    "    Args:\n",
    "        k: number of top-k similar vectors to retrieve from OpenSearch index\n",
    "        num_results: number of the top-k similar vectors to retrieve\n",
    "        index_name: index name in OpenSearch\n",
    "    \"\"\"\n",
    "\n",
    "    query_emb = bedrock_embedding.embedding_multimodal(text=text, image=image)\n",
    "\n",
    "    body = {\n",
    "        \"size\": k,\n",
    "        \"_source\": {\n",
    "            \"exclude\": [\"image_vector\"],\n",
    "        },\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"image_vector\": {\n",
    "                    \"vector\": query_emb,\n",
    "                    \"k\": k,\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    res = oss_client.search(index=index_name, body=body)\n",
    "    return res[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"leather sofa\"\n",
    "\n",
    "docs = find_similar_items(\n",
    "    oss_client,\n",
    "    bedrock_embedding,\n",
    "    index_name=index_name,\n",
    "    text=query_text,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"glass cup\"\n",
    "\n",
    "docs = find_similar_items(\n",
    "    oss_client,\n",
    "    bedrock_embedding,\n",
    "    index_name=index_name,\n",
    "    text=query_text,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base64 image\n",
    "query_image = encode_image_base64_from_file(file_path=\"./sample/rug.jpg\", format=\"JPEG\")\n",
    "\n",
    "docs = find_similar_items(\n",
    "    oss_client,\n",
    "    bedrock_embedding,\n",
    "    index_name=index_name,\n",
    "    image=query_image,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base64 image\n",
    "query_image = encode_image_base64_from_file(file_path=\"./sample/table.jpg\", format=\"JPEG\")\n",
    "\n",
    "docs = find_similar_items(\n",
    "    oss_client,\n",
    "    bedrock_embedding,\n",
    "    index_name=index_name,\n",
    "    image=query_image,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multimodal LLM을 통해 이미지를 해석하고 텍스트로 이미지 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = BedrockClaude()\n",
    "display_image(query_image)\n",
    "\n",
    "query_text = \"\"\"\n",
    "You are an expert at analyzing images in great detail. Your task is to carefully examine the provided \\\n",
    "image and generate a detailed, accurate textual description capturing all of the important elements and \\\n",
    "context present in the image. Pay close attention to any numbers, data, or quantitative information visible, \\\n",
    "and be sure to include those numerical values along with their semantic meaning in your description. \\\n",
    "Thoroughly read and interpret the entire image before providing your detailed caption describing the \\\n",
    "image content in text format. Strive for a truthful and precise representation of what is depicted\"\"\"\n",
    "\n",
    "gen_text = claude.invoke_llm_response(text=query_text, image=query_image)\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = find_similar_items(\n",
    "    oss_client,\n",
    "    bedrock_embedding,\n",
    "    index_name=index_name,\n",
    "    text=gen_text,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import gradio as gr\n",
    "import base64\n",
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks import AsyncIteratorCallbackHandler\n",
    "from common.utils.images import encode_image_base64_from_file, encode_image_base64\n",
    "from common.aws.claude import BedrockClaude\n",
    "\n",
    "\n",
    "PRODUCT_KEYWORD_SUGGESTION_TEMPLATE = '''\n",
    "You are an expert in suggesting product search terms. You suggest search terms in english for products that users want through conversations and questions with users.\n",
    "The output should be formatted as a JSON instance. Just answer json without any other explanation. Format the response as a JSON object with a key: \"keyword\"\n",
    "\n",
    "Here are the conversation between an Assistant and a user:\n",
    "<conversations>\n",
    "{conversations}\n",
    "</conversations>\n",
    "\n",
    "Here is a question from user:\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "'''\n",
    "\n",
    "PRODUCT_SEARCH_TEMPLATE = \"\"\"\n",
    "You are an expert who finds the products users want. Based on the user's question in <question>, refer to <information> and recommend a product to the user.\n",
    "If there is no accurate information, answer that the product does not exist.\n",
    "\n",
    "Information related to what the user requested is here:\n",
    "<information>\n",
    "{information}\n",
    "</information>\n",
    "\n",
    "Here is a question from user:\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\"\"\"\n",
    "\n",
    "claude = BedrockClaude()\n",
    "\n",
    "\n",
    "def add_message(history, message):\n",
    "    for x in message[\"files\"]:\n",
    "        history.append({\"role\": \"user\", \"content\": {\"path\": x}})\n",
    "\n",
    "    if message[\"text\"] is not None:\n",
    "        history.append({\"role\": \"user\", \"content\": message[\"text\"]})\n",
    "        \n",
    "    return history, gr.MultimodalTextbox(value=None, interactive=False)\n",
    "\n",
    "async def bot(history: list):\n",
    "    chat = claude.get_chat_model()\n",
    "\n",
    "    # extract a last message\n",
    "    last_message = history[-1][\"content\"]\n",
    "    last_message = \"관련 상품 추천해줘\" if len(last_message) == 0 else last_message\n",
    "\n",
    "    # extract a last image\n",
    "    image_path = None\n",
    "    for msg in reversed(history):\n",
    "        if msg[\"role\"] == \"assistant\":\n",
    "            break\n",
    "        if msg[\"role\"] == \"user\" and isinstance(msg[\"content\"], tuple):\n",
    "            image_path = msg[\"content\"][0]\n",
    "            break\n",
    "    image = encode_image_base64_from_file(image_path) if image_path is not None else None\n",
    "\n",
    "    # find search keyword\n",
    "    search_keyword = \"\"\n",
    "    try:\n",
    "        res = claude.invoke_llm_response(\n",
    "            text=PromptTemplate(\n",
    "                template=PRODUCT_KEYWORD_SUGGESTION_TEMPLATE,\n",
    "                input_variables=[\"question\", \"conversations\"]).format(question=last_message, conversations=\"\"),\n",
    "            image=image\n",
    "        )\n",
    "        \n",
    "        search_keyword = json.loads(res).get('keyword', '')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(search_keyword)\n",
    "\n",
    "    docs = find_similar_items(\n",
    "        oss_client,\n",
    "        bedrock_embedding,\n",
    "        index_name=index_name,\n",
    "        text=search_keyword,\n",
    "        image=image\n",
    "    )\n",
    "\n",
    "    # make a prompt\n",
    "    text = PromptTemplate(\n",
    "            template=PRODUCT_SEARCH_TEMPLATE,\n",
    "            input_variables=[\"question\", \"conversations\", \"information\"]\n",
    "        ).format(question=last_message, conversations=history, information=docs)\n",
    "    \n",
    "    # invoke LLM\n",
    "    prompt = claude.get_prompt(text=text, image=image)\n",
    "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "    async for chunk in chat.astream(prompt):\n",
    "        history[-1][\"content\"] += chunk.content\n",
    "        yield history    \n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(elem_id=\"chatbot\", bubble_full_width=False, type=\"messages\")\n",
    "\n",
    "    chat_input = gr.MultimodalTextbox(\n",
    "        interactive=True,\n",
    "        file_count=\"single\", # multiple\n",
    "        placeholder=\"Enter message or upload file...\",\n",
    "        show_label=False,\n",
    "    )\n",
    "\n",
    "    chat_msg = chat_input.submit(\n",
    "        add_message, [chatbot, chat_input], [chatbot, chat_input]\n",
    "    )\n",
    "    bot_msg = chat_msg.then(bot, chatbot, chatbot, api_name=\"bot_response\")\n",
    "    bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c97182bcee1c5a46c75e12f527516848bb4d812af65bc6ddf5c082f318f5a83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
